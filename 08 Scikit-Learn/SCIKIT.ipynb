{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "  # Label Encoder\n",
    "  # One Hot Encoding\n",
    "  # Binarization\n",
    "  # Scaling\n",
    "  # Standardization\n",
    "  # Min-Max Scaling\n",
    "\n",
    "# Handling Missing Values\n",
    "  # Filling Missing Imputers\n",
    "    \n",
    "# Split Train and Test\n",
    "  # Train Test Split\n",
    "\n",
    "# Machine Learning    \n",
    "  # Linear Regression\n",
    "  # Polynominal : Generating PolyNominal Features\n",
    "  # Logistic Regression\n",
    "  # SGDRegressor\n",
    "  # SGD Classifer\n",
    "  # Decision Tree : Regresssor\n",
    "  # Decision Tree : Classifier\n",
    "  # Naive Bayes\n",
    "    # GaussianNB\n",
    "    # BernoulliNB\n",
    "    # MultinomialNB\n",
    "    \n",
    "  # SVM : Linear SVC\n",
    "  # Cross Validation :KFOld\n",
    "  # KNN\n",
    "    \n",
    "  # Ensemble Learning\n",
    "    # Random Forest\n",
    "    # AdaBoost\n",
    "    # Gradient Boosting\n",
    "    # XG Boost\n",
    "\n",
    "# Regularization\n",
    "  # L1(Lasso Regularization)\n",
    "  # L2(Ridge Regularization)\n",
    "  # Elastic Regularization\n",
    "  # Cross Validation Score\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "  # GridSearch CV\n",
    "  # Random Search CV\n",
    "\n",
    "# Unsupervised Learning\n",
    "  # Clustering \n",
    "    # K-Means Clustering\n",
    "  \n",
    "  # Dimentionality Reduction\n",
    "    # Dimentionality Reduction : PCA\n",
    "    # Dimentionality Reduction: FactorAnalysis\n",
    "    # Dimentionality Reduction: SVD\n",
    "    # Dimentionality Reduction: t-SNE\n",
    "    # Dimentionality Reduction: LDA\n",
    "\n",
    "# Metrics\n",
    "  # Regression\n",
    "    # Metrics : Mean Squared Error\n",
    "    # Metrics : Mean Absolute Error\n",
    "    # Metrics : R2 Score\n",
    "    \n",
    "  # Classification  \n",
    "    # Metrics : Explained Variance Score\n",
    "    # Metrics : Accuracy\n",
    "    # Metrics : Confusion Metrix\n",
    "    # Metrics : Classification Report\n",
    "    # Metrics : Receiver Operator Characteristic\n",
    "    # Metrics : ROC_AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "encoded_value = le.fit_transform([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarization\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarized = Binarizer(threshold=1.4)\n",
    "\n",
    "binarized.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-3,3))\n",
    "scaler.fit([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])\n",
    "\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing Imputers\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# strategy:= mean, most_frequent, median and constant\n",
    "\n",
    "imp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "\n",
    "from sklearn.model_selection import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "model = lr.fit(X_train, y_train)\n",
    "\n",
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation Score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(model,X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "logisticRegr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1(Lasso Regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg.fit(X,y)\n",
    "predicted = lasso_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2(Ridge Regularization)\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=1,solver=\"cholesky\")\n",
    "ridge_reg.fit(X,y)\n",
    "predicted = ridge_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Polynominal : Generating PolyNominal Features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y)\n",
    "y_poly_pred = model.predict(x_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(penalty=\"l2\")\n",
    "sgd_reg.fit(X,y)\n",
    "predicted = sgd_reg.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD Classifer\n",
    "  \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "\n",
    "clf.fit(X, y)\n",
    "print(clf.predict([[2., 2.]]))\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Regularization\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.1,l1_ratio=0.5)\n",
    "elastic_net.fit(X,y)\n",
    "predicted = elastic_net.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree : Regresssor\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree : Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\",max_depth=3)\n",
    "clf.fit(X_train,y_train)\n",
    "print(clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM : Linear SVC\n",
    "\n",
    "#import the necessary modules\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#create an object of type LinearSVC\n",
    "svc_model = LinearSVC(random_state=0)\n",
    "\n",
    "#train the algorithm on training data and predict using the testing data\n",
    "pred = svc_model.fit(data_train, target_train).predict(data_test)\n",
    "\n",
    "#print the accuracy score of the model\n",
    "print(\"LinearSVC accuracy : \",accuracy_score(target_test, pred, malize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation :KFOld\n",
    "\n",
    "from sklearn import model_selection  \n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10,random_state=7)\n",
    "model = LinearRegression()\n",
    "\n",
    "results = model_selection.cross_val_score(model,X,Y,cv=kfold,scoring='neg_mean_squared_error')\n",
    "print(\"Linear Regression along With KFold:\",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#create object of the lassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#Train the algorithm\n",
    "neigh.fit(X, y)\n",
    "\n",
    "# predict the response\n",
    "pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search CV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "           'criterion': ['gini','entropy'],\n",
    "           'max_features' : ['auto','log2',None],\n",
    "           'min_samples_split' : [2,10,25,100,200],\n",
    "            'max_depth' : [5,10,15,None]\n",
    "         }]\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=param_grid,scoring='accuracy',cv=10)\n",
    "\n",
    "gs.fit(X,y)\n",
    "print(gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering : K-Means\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3)\n",
    "km.fit(X)\n",
    "\n",
    "# Show the centroids\n",
    "print(km.cluster_centers_)\n",
    "print(km.labels_)\n",
    "print(km.predict([[0,0],[12,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimentionality Reduction : PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(data)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimentionality Reduction: FactorAnalysis\n",
    "  \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "fa = FactorAnalysis(n_components=2)\n",
    "iris_two_dim = fa.fit_transform(X)\n",
    "\n",
    "iris_two_dim[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimentionality Reduction: SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(2)\n",
    "\n",
    "transformed = svd.fit_transform(X)\n",
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimentionality Reduction: t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimentionality Reduction: LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Mean Squared Error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Mean Absolute Error\n",
    "\n",
    "from sklearn.metrics import\n",
    "print(mean_absolute_error(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : R2 Score\n",
    "\n",
    "  from sklearn.metrics import r2_score\n",
    "  print(r2_score(y,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Explained Variance Score\n",
    "\n",
    "from sklearn.metrics import explained_variance_score\n",
    "print(explained_variance_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics : Confusion Metrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Classification Report\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "classification_report(y, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : Receiver Operator Characteristic\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "auc = roc_auc_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics : ROC_AUC \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y, y_pred)\n",
    "\n",
    "pyplot.plot(fpr, tpr, marker='.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
